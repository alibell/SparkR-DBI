name: test
on:
  push:
    branches: ["main"]
  pull_request:
    branches: ["main"]
permissions:
  contents: read
jobs:
  test:
    runs-on: ubuntu-latest
    name: ${{ matrix.config.name }}
    strategy:
      fail-fast: false
      matrix:
        config:
          - {spark: '3.3.0', hadoop: '3', r: 'release', name: 'Spark 3.3'}
          - {spark: '3.2.2', hadoop: '3.2', r: 'release', name: 'Spark 3.2'}
          - {spark: '3.1.3', hadoop: '3.2', r: 'release', name: 'Spark 3.1'}
          - {spark: '2.4.0', hadoop: '2.7', r: '3.5.1', name: 'Spark 2.4'}
          - {spark: '2.2.1', hadoop: '2.7', r: '3.5.1', name: 'Spark 2.2'}
    steps:
      - uses: actions/checkout@v2
      - uses: r-lib/actions/setup-r@v2
        with:
          r-version: ${{ matrix.config.r }}
          use-public-rspm: true
      - uses: actions/setup-python@v2
        with:
          python-version: '3.8'
      - uses: actions/setup-java@v1
        with:
          java-version: '11'
      - uses: vemonet/setup-spark@v1
        with:
          spark-version: ${{ matrix.config.spark }}
          hadoop-version: ${{ matrix.config.hadoop }}
      - name: Installating SparkR
        run: |
          R CMD INSTALL $SPARK_HOME/R/lib/SparkR
      - uses: r-lib/actions/setup-r-dependencies@v2
        with:
          cache: true
          need: true
          pak-version: devel
          extra-packages: |
            any::devtools
            SparkR=?ignore
      - name: Running test
        run: |
          devtools::load_all()
          devtools::test()
        shell: Rscript {0}
